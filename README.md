# STARVE: Style TrAnsfeR for VidEos

This is the final project for class 
[CSCI 1430: Introduction to Computer Vision](https://browncsci1430.github.io/webpage/).

Team members (alphabetical by first name): 
[Yicheng Shi](https://github.com/yshi77),
[Yuchen Zhou](https://github.com/zhou671), 
[Yue Wang](https://github.com/yuewangpl), 
and [Zichuan Wang](https://github.com/GuardianWang).

In this project, we realize video style transfer in TensorFlow2.
Our work is heavily based on paper 
[Artistic style transfer for videos](http://arxiv.org/abs/1604.08610)
and [this repo](https://github.com/manuelruder/artistic-videos) 
written in Lua and C++.
We also refer to in this 
[tutorial](https://www.tensorflow.org/tutorials/generative/style_transfer)
for basic functions.

## Optic Flow

If calculate optic flow with 2 CPU cores, it takes 35s per frame on average.
 
`Optic flow: 100% 120/120 [1:09:26<00:00, 34.72s/it]`
